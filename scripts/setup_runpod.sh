#!/bin/bash
# Setup script for 8x H100 environment
# This script installs dependencies, configures credentials, and prepares the environment
#
# ============================================================================
# Setup Instructions
# ============================================================================
# 1. SSH into the machine and run:
#    cd ~/sdpo
#    ./scripts/setup_runpod.sh
#    ./scripts/run_sdpo.sh
#
# ============================================================================
# Expected directory structure:
#   ~/sdpo/                   # git repo cloned here
#       ├── scripts/          # This setup script and run script
#       ├── verl/             # verl with SDPO modifications
#       ├── datasets/         # Pre-prepared datasets
#       │   └── lcb_v6/
#       │       ├── train.parquet
#       │       └── test.parquet
#       └── checkpoints/      # Will be created for saving checkpoints

set -e

echo "=============================================="
echo "SDPO Setup (8x H100 Full Fine-tuning)"
echo "=============================================="

# Get script directory and workspace root
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
# Script is in sdpo/scripts/, so parent is sdpo/
SDPO_ROOT="$(dirname "$SCRIPT_DIR")"
VERL_DIR="${SDPO_ROOT}/verl"

echo "VERL_DIR:  $VERL_DIR"
echo "SDPO_ROOT: $SDPO_ROOT"

# ============================================================================
# WandB Configuration (Interactive)
# ============================================================================
echo ""
echo "=============================================="
echo "Weights & Biases (WandB) Configuration"
echo "=============================================="
echo ""
echo "WandB tracks training metrics and visualizations."
echo "Get your API key from: https://wandb.ai/authorize"
echo ""

if [ -n "$WANDB_API_KEY" ]; then
    echo "WANDB_API_KEY is already set (from environment)"
else
    echo "Enter your WandB API key (or press Enter to skip):"
    read -r -s WANDB_API_KEY_INPUT
    echo ""
    if [ -n "$WANDB_API_KEY_INPUT" ]; then
        export WANDB_API_KEY="$WANDB_API_KEY_INPUT"
        echo "✓ WANDB_API_KEY set"
    else
        echo "⚠ WANDB_API_KEY not set - will use console logging only"
    fi
fi

if [ -n "$WANDB_PROJECT" ]; then
    echo "WANDB_PROJECT is already set: $WANDB_PROJECT"
else
    echo "Enter WandB project name (default: SDPO):"
    read -r WANDB_PROJECT_INPUT
    if [ -n "$WANDB_PROJECT_INPUT" ]; then
        export WANDB_PROJECT="$WANDB_PROJECT_INPUT"
    else
        export WANDB_PROJECT="SDPO"
    fi
    echo "✓ WANDB_PROJECT: $WANDB_PROJECT"
fi

# ============================================================================
# Hugging Face Configuration (Interactive)
# ============================================================================
echo ""
echo "=============================================="
echo "Hugging Face Configuration"
echo "=============================================="
echo ""
echo "To automatically upload checkpoints after training, you need:"
echo "  1. HF_TOKEN  - Your Hugging Face access token"
echo "  2. HF_REPO_ID - Target repository (e.g., username/model-name)"
echo ""

# Check if already set
if [ -n "$HF_TOKEN" ]; then
    echo "HF_TOKEN is already set (from environment)"
else
    echo "Enter your Hugging Face token (or press Enter to skip):"
    echo "(Get token from: https://huggingface.co/settings/tokens)"
    read -r -s HF_TOKEN_INPUT
    echo ""
    if [ -n "$HF_TOKEN_INPUT" ]; then
        export HF_TOKEN="$HF_TOKEN_INPUT"
        echo "✓ HF_TOKEN set"
    else
        echo "⚠ HF_TOKEN not set - checkpoints won't be uploaded automatically"
    fi
fi

if [ -n "$HF_REPO_ID" ]; then
    echo "HF_REPO_ID is already set: $HF_REPO_ID"
else
    echo ""
    echo "Enter your Hugging Face repo ID (e.g., your-username/sdpo-qwen3-4b):"
    read -r HF_REPO_ID_INPUT
    if [ -n "$HF_REPO_ID_INPUT" ]; then
        export HF_REPO_ID="$HF_REPO_ID_INPUT"
        echo "✓ HF_REPO_ID set: $HF_REPO_ID"
    else
        echo "⚠ HF_REPO_ID not set - checkpoints won't be uploaded automatically"
    fi
fi

# ============================================================================
# Fixed Configuration: 8x H100
# ============================================================================
N_GPUS=8
LORA_RANK=0
TRAIN_BATCH_SIZE=32
MODEL_PATH="Qwen/Qwen3-4B"

echo ""
echo "=============================================="
echo "Hardware Configuration (Fixed)"
echo "=============================================="
echo "  GPUs:       8x H100 80GB"
echo "  Mode:       Full Fine-tuning (no LoRA)"
echo "  Model:      $MODEL_PATH"
echo "  Batch Size: $TRAIN_BATCH_SIZE"
echo "=============================================="

# Save to .env file for persistence
ENV_FILE="${SDPO_ROOT}/.env"
echo ""
echo "Saving configuration to ${ENV_FILE}..."
cat > "$ENV_FILE" << EOF
# SDPO Environment Configuration
# Generated by setup_runpod.sh on $(date)
# Fixed: 8x H100 Full Fine-tuning

# WandB credentials
export WANDB_API_KEY="${WANDB_API_KEY}"
export WANDB_PROJECT="${WANDB_PROJECT:-SDPO}"

# Hugging Face credentials
export HF_TOKEN="${HF_TOKEN}"
export HF_REPO_ID="${HF_REPO_ID}"

# Training configuration (fixed for 8x H100)
export MODEL_PATH="${MODEL_PATH}"
export TASK="${TASK:-lcb_v6}"
export N_GPUS="${N_GPUS}"
export TOTAL_EPOCHS="${TOTAL_EPOCHS:-30}"
export LORA_RANK="${LORA_RANK}"
export TRAIN_BATCH_SIZE="${TRAIN_BATCH_SIZE}"
export LEARNING_RATE="${LEARNING_RATE:-1e-5}"
EOF

echo "✓ Configuration saved to ${ENV_FILE}"

# ============================================================================
# Install Dependencies
# ============================================================================
echo ""
echo "=============================================="
echo "Installing system tools..."
echo "=============================================="

# Install tmux for persistent sessions (training survives SSH disconnect)
if ! command -v tmux &> /dev/null; then
    echo "Installing tmux..."
    apt-get update -qq && apt-get install -y -qq tmux 2>/dev/null || sudo apt-get update -qq && sudo apt-get install -y -qq tmux
fi
echo "✓ tmux ready"

echo ""
echo "=============================================="
echo "Installing Python dependencies..."
echo "=============================================="

# Check if running in verl Docker image
if python -c "import vllm" 2>/dev/null; then
    echo "✓ vllm already installed"
else
    echo "vllm not found, installing heavy dependencies..."
    pip install vllm ray[default] --quiet
    pip install flash-attn --no-build-isolation --quiet || echo "flash-attn installation failed"
fi

# Install verl with local SDPO modifications (ALWAYS needed!)
echo "Installing verl with SDPO modifications..."
cd "$VERL_DIR"
pip install --no-deps -e . --quiet

# Install dependencies that may be missing
echo "Installing additional dependencies..."
pip install --quiet \
    hydra-core \
    omegaconf \
    peft \
    datasets \
    wandb \
    huggingface_hub \
    accelerate

echo ""
echo "✓ Dependencies ready!"

# Verify critical imports
echo ""
echo "Verifying installations..."
python -c "import verl; print('✓ verl')" || echo "❌ verl import failed"
python -c "import vllm; print('✓ vllm')" || echo "❌ vllm import failed"
python -c "import ray; print('✓ ray')" || echo "❌ ray import failed"
python -c "import hydra; print('✓ hydra')" || echo "❌ hydra import failed"
python -c "import peft; print('✓ peft')" || echo "❌ peft import failed"
python -c "import wandb; print('✓ wandb')" || echo "❌ wandb import failed"

# ============================================================================
# Create checkpoint directory
# ============================================================================
echo ""
echo "Creating checkpoint directory..."
mkdir -p "${SDPO_ROOT}/checkpoints"

# ============================================================================
# Verify Data
# ============================================================================
echo ""
echo "=============================================="
echo "Checking datasets..."
echo "=============================================="
if [ -d "${SDPO_ROOT}/datasets/lcb_v6" ]; then
    echo "✓ Found lcb_v6 dataset:"
    ls -lh "${SDPO_ROOT}/datasets/lcb_v6/"
else
    echo "⚠ WARNING: lcb_v6 dataset not found at ${SDPO_ROOT}/datasets/lcb_v6/"
    echo "Available directories:"
    ls -la "${SDPO_ROOT}/" 2>/dev/null || echo "  (sdpo root not found)"
fi

# ============================================================================
# Summary
# ============================================================================
echo ""
echo "=============================================="
echo "✅ Setup Complete!"
echo "=============================================="
echo ""
echo "Hardware Configuration:"
echo "  GPUs:        8x H100 80GB"
echo "  Mode:        Full Fine-tuning"
echo "  Model:       $MODEL_PATH"
echo "  Batch Size:  $TRAIN_BATCH_SIZE"
echo ""
echo "Credentials:"
echo "  WANDB_API_KEY:  ${WANDB_API_KEY:+[SET]}${WANDB_API_KEY:-[NOT SET]}"
echo "  WANDB_PROJECT:  ${WANDB_PROJECT:-SDPO}"
echo "  HF_TOKEN:       ${HF_TOKEN:+[SET]}${HF_TOKEN:-[NOT SET]}"
echo "  HF_REPO_ID:     ${HF_REPO_ID:-[NOT SET]}"
echo ""
echo "Directory structure:"
echo "  ${SDPO_ROOT}/"
echo "  ├── verl/            # Code"
echo "  ├── datasets/lcb_v6/ # Training data"
echo "  ├── checkpoints/     # Checkpoints will be saved here"
echo "  └── .env             # Your configuration"
echo ""
echo "=============================================="
echo "Ready to train! Run:"
echo "=============================================="
echo ""
echo "  source ${ENV_FILE}  # Load your credentials"
echo "  ${SCRIPT_DIR}/run_sdpo.sh"
echo ""
if [ -n "$HF_TOKEN" ] && [ -n "$HF_REPO_ID" ]; then
    echo "After training completes:"
    echo "  - Checkpoint will be uploaded to: https://huggingface.co/${HF_REPO_ID}"
else
    echo "⚠ Note: HF credentials not fully configured."
    echo "  Checkpoints will be saved locally but NOT uploaded."
    echo "  To fix, edit ${ENV_FILE} and add your credentials."
fi
echo ""
